# -*- coding: utf-8 -*-
"""Logistic Regression Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XVwA13oJgFsaf6hCczlOUanznGx2Ujrf
"""

import numpy as np

class Logistic_Regression():
  def __init__(self,learning_rate,no_of_iterations):
    #initiating aplha and no of iterations
    self.learning_rate = learning_rate
    self.no_of_iterations = no_of_iterations


  def fit(self,X,Y):
    #m ----> rows(data points)
    #n ----> columns(features)
    self.m,self.n = X.shape

    #initaiting weight and bias
    self.w = np.zeros(self.n)
    self.b = 0

    self.X = X
    self.Y = Y

    #implement gradient descent for optimization
    for i in range(self.no_of_iterations):
      self.update_weights()

  def update_weights(self):
    #Sigmoid function
    Y_hat = 1/(np.exp(-(self.X.dot(self.w)+self.b)))

    #derivatives
    dw = (1/self.m)*np.dot(self.X.T,(Y_hat - self.Y))
    db = (1/self.m)*np.sum(Y_hat - self.Y)

    #updating w and b
    self.w = self.w -self.learning_rate*dw
    self.b = self.b -self.learning_rate*db

  def predict(self,X):
    Y_pred = 1/(np.exp(-(X.dot(self.w)+self.b)))
    Y_pred = np.where(Y_pred > 0.5,1,0)
    return Y_pred